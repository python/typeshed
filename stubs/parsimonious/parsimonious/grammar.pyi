from collections import OrderedDict
from typing import Any, Callable, Mapping, NoReturn
from typing_extensions import Self

from parsimonious.exceptions import BadGrammar as BadGrammar, UndefinedLabel as UndefinedLabel
from parsimonious.expressions import (
    _CALLABLE_TYPE as _CALLABLE_TYPE,
    Expression as Expression,
    Literal as Literal,
    Lookahead as Lookahead,
    Not as Not,
    OneOf as OneOf,
    OneOrMore as OneOrMore,
    Optional as Optional,
    Regex as Regex,
    Sequence as Sequence,
    TokenMatcher as TokenMatcher,
    ZeroOrMore as ZeroOrMore,
    expression as expression,
    is_callable as is_callable,
)
from parsimonious.nodes import Node as Node, NodeVisitor as NodeVisitor
from parsimonious.utils import evaluate_string as evaluate_string
from six import text_type

class Grammar(OrderedDict):
    default_rule: Expression | Any
    def __init__(self, rules: str = ..., **more_rules: Expression | _CALLABLE_TYPE) -> None: ...
    def default(self, rule_name: str) -> Grammar: ...
    def parse(self, text: str, pos: int = ...) -> Node: ...
    def match(self, text: str, pos: int = ...) -> Node: ...

class TokenGrammar(Grammar): ...
class BootstrappingGrammar(Grammar): ...

rule_syntax: str

class LazyReference(text_type):
    name: str

class RuleVisitor(NodeVisitor):
    quantifier_classes: dict[str, Expression]
    visit_expression: Callable[[Self, Node, list[Any]], Any]
    visit_term: Callable[[Self, Node, list[Any]], Any]
    visit_atom: Callable[[Self, Node, list[Any]], Any]
    custom_rules: dict[str, Expression]
    def __init__(self, custom_rules: Mapping[str, Expression] | None = ...) -> None: ...
    def visit_rules(self, node: Node, rules_list: list[Any]) -> tuple[OrderedDict[str, Expression], Expression | None]: ...
    def visit_rule(self, node: Node, rule: list[Any]) -> Expression: ...
    def visit_label(self, node: Node, label: list[Any]) -> str: ...
    def visit_ored(self, node: Node, ored: list[Any]) -> OneOf: ...
    def visit_or_term(self, node: Node, or_term: list[Any]) -> Expression: ...
    def visit_sequence(self, node: Node, sequence: list[Any]) -> Sequence: ...
    def visit_not_term(self, node: Node, not_term: list[Any]) -> Not: ...
    def visit_lookahead_term(self, node: Node, lookahead_term: list[Any]) -> Lookahead: ...
    def visit_quantified(self, node: Node, quantified: list[Any]) -> Expression: ...
    def visit_quantifier(self, node: Node, quantifier: list[Any]) -> Node: ...
    def visit_reference(self, node: Node, reference: list[Any]) -> LazyReference: ...
    def visit_literal(self, node: Node, literal: list[Any]) -> Literal: ...
    def visit_spaceless_literal(self, spaceless_literal: Node, visited_children: list[Any]) -> Literal: ...
    def visit_regex(self, node: Node, regex: list[Any]) -> Regex: ...
    def visit_parenthesized(self, node: Node, parenthesized: list[Any]) -> Expression: ...
    def generic_visit(self, node: Node, visited_children: list[Any]) -> list[Any] | Node: ...

class TokenRuleVisitor(RuleVisitor):
    def visit_spaceless_literal(self, spaceless_literal: Node, visited_children: list[Any]) -> TokenMatcher: ...
    def visit_regex(self, node: Node, regex: list[Any]) -> NoReturn: ...

rule_grammar: Grammar
