from collections.abc import Iterator
from typing import ClassVar, Final, Literal

from .error import MarkedYAMLError, StreamMark
from .loader import _Loader
from .main import YAML
from .reader import Reader
from .tokens import (
    AliasToken,
    AnchorToken,
    BlockEndToken,
    DirectiveToken,
    DocumentEndToken,
    DocumentStartToken,
    FlowMappingEndToken,
    FlowMappingStartToken,
    FlowSequenceEndToken,
    FlowSequenceStartToken,
    ScalarToken,
    TagToken,
    Token,
    _BlockScalarStyle,
    _FlowScalarStyle,
    _TagDirective,
    _VersionTuple,
)

__all__ = ["Scanner", "RoundTripScanner", "ScannerError"]

class ScannerError(MarkedYAMLError): ...

class SimpleKey:
    token_number: int
    required: bool
    index: int
    line: int
    column: int
    mark: StreamMark
    def __init__(self, token_number: int, required: bool, index: int, line: int, column: int, mark: StreamMark) -> None: ...

class Scanner:
    loader: YAML | _Loader | None
    first_time: bool
    def __init__(self, loader: YAML | _Loader | None = None) -> None: ...
    @property
    def flow_level(self) -> int: ...
    done: bool
    flow_context: list[str]
    tokens: list[Token]
    tokens_taken: int
    indent: int
    indents: list[int]
    allow_simple_key: bool
    possible_simple_keys: dict[int, SimpleKey]
    yaml_version: _VersionTuple | None
    tag_directives: list[_TagDirective]
    def reset_scanner(self) -> None: ...
    @property
    def reader(self) -> Reader: ...
    @property
    def scanner_processing_version(self) -> _VersionTuple: ...
    def check_token(self, *choices: type[Token]) -> bool: ...
    def peek_token(self) -> Token: ...
    def get_token(self) -> Token: ...
    def need_more_tokens(self) -> bool: ...
    def fetch_comment(self, comment) -> None: ...
    def fetch_more_tokens(self) -> None: ...
    def next_possible_simple_key(self) -> int | None: ...
    def stale_possible_simple_keys(self) -> None: ...
    def save_possible_simple_key(self) -> None: ...
    def remove_possible_simple_key(self) -> None: ...
    def unwind_indent(self, column: int) -> None: ...
    def add_indent(self, column: int) -> bool: ...
    def fetch_stream_start(self) -> None: ...
    def fetch_stream_end(self) -> None: ...
    def fetch_directive(self) -> None: ...
    def fetch_document_start(self) -> None: ...
    def fetch_document_end(self) -> None: ...
    def fetch_document_indicator(self, TokenClass: type[DocumentStartToken | DocumentEndToken]) -> None: ...
    def fetch_flow_sequence_start(self) -> None: ...
    def fetch_flow_mapping_start(self) -> None: ...
    def fetch_flow_collection_start(
        self, TokenClass: type[FlowSequenceStartToken | FlowMappingStartToken], to_push: str
    ) -> None: ...
    def fetch_flow_sequence_end(self) -> None: ...
    def fetch_flow_mapping_end(self) -> None: ...
    def fetch_flow_collection_end(self, TokenClass: type[FlowSequenceEndToken | FlowMappingEndToken]) -> None: ...
    def fetch_flow_entry(self) -> None: ...
    def fetch_block_entry(self) -> None: ...
    def fetch_key(self) -> None: ...
    def fetch_value(self) -> None: ...
    def fetch_alias(self) -> None: ...
    def fetch_anchor(self) -> None: ...
    def fetch_tag(self) -> None: ...
    def fetch_literal(self) -> None: ...
    def fetch_folded(self) -> None: ...
    def fetch_block_scalar(self, style: _BlockScalarStyle) -> None: ...
    def fetch_single(self) -> None: ...
    def fetch_double(self) -> None: ...
    def fetch_flow_scalar(self, style: _FlowScalarStyle) -> None: ...
    def fetch_plain(self) -> None: ...
    def check_directive(self) -> Literal[True] | None: ...
    def check_document_start(self) -> Literal[True] | None: ...
    def check_document_end(self) -> Literal[True] | None: ...
    def check_block_entry(self) -> bool: ...
    def check_key(self) -> bool: ...
    def check_value(self) -> bool: ...
    def check_plain(self) -> bool: ...
    def scan_to_next_token(self) -> tuple[str, StreamMark, StreamMark] | None: ...
    def scan_directive(self) -> DirectiveToken: ...
    def scan_directive_name(self, start_mark: StreamMark) -> str: ...
    def scan_yaml_directive_value(self, start_mark: StreamMark) -> _VersionTuple: ...
    def scan_yaml_directive_number(self, start_mark: StreamMark) -> int: ...
    def scan_tag_directive_value(self, start_mark: StreamMark) -> _TagDirective: ...
    def scan_tag_directive_handle(self, start_mark: StreamMark) -> str: ...
    def scan_tag_directive_prefix(self, start_mark: StreamMark) -> str: ...
    def scan_directive_ignored_line(self, start_mark: StreamMark) -> None: ...
    def scan_anchor(self, TokenClass: type[AliasToken | AnchorToken]) -> AliasToken | AnchorToken: ...
    def scan_tag(self) -> TagToken: ...
    def scan_block_scalar(self, style: _BlockScalarStyle, rt: bool | None = False) -> ScalarToken: ...
    def scan_block_scalar_indicators(self, start_mark: StreamMark) -> tuple[bool | None, int | None]: ...
    def scan_block_scalar_ignored_line(self, start_mark: StreamMark) -> str | None: ...
    def scan_block_scalar_indentation(self) -> tuple[list[str], int, StreamMark]: ...
    def scan_block_scalar_breaks(self, indent: int) -> tuple[list[str], StreamMark]: ...
    def scan_flow_scalar(self, style: _FlowScalarStyle) -> ScalarToken: ...
    ESCAPE_REPLACEMENTS: Final[dict[str, str]]
    ESCAPE_CODES: Final[dict[str, int]]
    def scan_flow_scalar_non_spaces(self, double: bool, start_mark: StreamMark) -> list[str]: ...
    def scan_flow_scalar_spaces(self, double: bool, start_mark: StreamMark) -> list[str]: ...
    def scan_flow_scalar_breaks(self, double: bool, start_mark: StreamMark) -> list[str]: ...
    def scan_plain(self) -> ScalarToken: ...
    def scan_plain_spaces(self, indent: int, start_mark: StreamMark) -> list[str]: ...
    def scan_tag_handle(self, name: str, start_mark: StreamMark) -> str: ...
    def scan_tag_uri(self, name: str, start_mark: StreamMark) -> str: ...
    def scan_uri_escapes(self, name: str, start_mark: StreamMark) -> str: ...
    def scan_line_break(self) -> str: ...

class RoundTripScanner(Scanner):
    def check_token(self, *choices: type[Token]) -> bool: ...
    def peek_token(self) -> Token: ...
    def get_token(self) -> Token: ...
    def fetch_comment(self, comment: tuple[str, StreamMark, StreamMark]) -> None: ...
    def scan_to_next_token(self) -> tuple[str, StreamMark, StreamMark]: ...
    def scan_line_break(self, empty_line: bool = False) -> str: ...
    def scan_block_scalar(self, style: _BlockScalarStyle, rt: bool | None = True) -> ScalarToken: ...
    def scan_uri_escapes(self, name: str, start_mark: StreamMark) -> str: ...

class CommentBase:  # RTSC
    name: ClassVar[str]
    value: str
    line: int
    column: int
    used: str
    def __init__(self, value: str, line: int, column: int) -> None: ...
    def set_used(self, v: str = "+") -> None: ...
    def set_assigned(self) -> None: ...
    def info(self) -> str: ...

class EOLComment(CommentBase):
    name: Final = "EOLC"

class FullLineComment(CommentBase):
    name: Final = "FULL"

class BlankLineComment(CommentBase):
    name: Final = "BLNK"

class ScannedComments:  # RTSC
    comments: dict[int, CommentBase]
    unused: list[int]
    def __init__(self) -> None: ...
    def add_eol_comment(self, comment: str, column: int, line: int) -> EOLComment: ...
    def add_blank_line(self, comment: str, column: int, line: int) -> BlankLineComment: ...
    def add_full_line_comment(self, comment: str, column: int, line: int) -> FullLineComment: ...
    def __getitem__(self, idx: int) -> CommentBase: ...
    def last(self) -> str: ...
    def any_unprocessed(self) -> bool: ...
    def unprocessed(self, use: bool = False) -> Iterator[tuple[int, CommentBase]]: ...
    def assign_pre(self, token: Token) -> bool: ...
    def assign_eol(self, tokens: list[Token]) -> None: ...
    def assign_post(self, token: BlockEndToken) -> bool: ...
    def str_unprocessed(self) -> str: ...

class RoundTripScannerSC(Scanner):
    comments: ScannedComments | None
    def get_token(self) -> Token: ...
    def need_more_tokens(self) -> bool: ...
    def scan_to_next_token(self) -> None: ...
    def scan_empty_or_full_line_comments(self) -> None: ...
    def scan_block_scalar_ignored_line(self, start_mark) -> None: ...
