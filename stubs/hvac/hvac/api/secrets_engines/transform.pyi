from _typeshed import Incomplete

from hvac.api.vault_api_base import VaultApiBase

DEFAULT_MOUNT_POINT: str

class Transform(VaultApiBase):
    def create_or_update_role(self, name, transformations, mount_point=...): ...
    def read_role(self, name, mount_point=...): ...
    def list_roles(self, mount_point=...): ...
    def delete_role(self, name, mount_point=...): ...
    def create_or_update_transformation(
        self,
        name,
        transform_type,
        template,
        tweak_source: str = ...,
        masking_character: str = ...,
        allowed_roles: Incomplete | None = ...,
        mount_point=...,
    ): ...
    def create_or_update_fpe_transformation(self, name, template, tweak_source: str = ...): ...
    def create_or_update_masking_transformation(self, name, template, masking_character: str = ...): ...
    def create_or_update_tokenization_transformation(
        self,
        name,
        max_ttl: int = ...,
        mapping_mode: str = ...,
        allowed_roles: Incomplete | None = ...,
        stores: Incomplete | None = ...,
        mount_point=...,
    ): ...
    def read_transformation(self, name, mount_point=...): ...
    def list_transformations(self, mount_point=...): ...
    def delete_transformation(self, name, mount_point=...): ...
    def create_or_update_template(self, name, template_type, pattern, alphabet, mount_point=...): ...
    def read_template(self, name, mount_point=...): ...
    def list_templates(self, mount_point=...): ...
    def delete_template(self, name, mount_point=...): ...
    def create_or_update_alphabet(self, name, alphabet, mount_point=...): ...
    def read_alphabet(self, name, mount_point=...): ...
    def list_alphabets(self, mount_point=...): ...
    def delete_alphabet(self, name, mount_point=...): ...
    def create_or_update_tokenization_store(
        self,
        name,
        driver,
        connection_string,
        username: Incomplete | None = ...,
        password: Incomplete | None = ...,
        type: str = ...,
        supported_transformations: Incomplete | None = ...,
        schema: str = ...,
        max_open_connections: int = ...,
        max_idle_connections: int = ...,
        max_connection_lifetime: int = ...,
        mount_point=...,
    ): ...
    def encode(
        self,
        role_name,
        value: Incomplete | None = ...,
        transformation: Incomplete | None = ...,
        tweak: Incomplete | None = ...,
        batch_input: Incomplete | None = ...,
        mount_point=...,
    ): ...
    def decode(
        self,
        role_name,
        value: Incomplete | None = ...,
        transformation: Incomplete | None = ...,
        tweak: Incomplete | None = ...,
        batch_input: Incomplete | None = ...,
        mount_point=...,
    ): ...
    def validate_token(self, role_name, value, transformation, batch_input: Incomplete | None = ..., mount_point=...): ...
    def check_tokenization(self, role_name, value, transformation, batch_input: Incomplete | None = ..., mount_point=...): ...
    def retrieve_token_metadata(
        self, role_name, value, transformation, batch_input: Incomplete | None = ..., mount_point=...
    ): ...
    def snapshot_tokenization_state(self, name, limit: int = ..., continuation: str = ...): ...
    def restore_tokenization_state(self, name, values, mount_point=...): ...
    def export_decoded_tokenization_state(self, name, limit: int = ..., continuation: str = ...): ...
    def rotate_tokenization_key(self, transform_name, mount_point=...): ...
    def update_tokenization_key_config(self, transform_name, min_decryption_version, mount_point=...): ...
    def list_tokenization_key_configuration(self, mount_point=...): ...
    def read_tokenization_key_configuration(self, transform_name, mount_point=...): ...
    def trim_tokenization_key_version(self, transform_name, min_available_version, mount_point=...): ...
