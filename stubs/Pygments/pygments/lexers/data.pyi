from pygments.lexer import ExtendedRegexLexer, Lexer, LexerContext
from typing import Any, Optional

class YamlLexerContext(LexerContext):
    indent_stack: Any = ...
    indent: int = ...
    next_indent: int = ...
    block_scalar_indent: Any = ...
    def __init__(self, *args: Any, **kwds: Any) -> None: ...

class YamlLexer(ExtendedRegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    def something(token_class: Any): ...
    def reset_indent(token_class: Any): ...
    def save_indent(token_class: Any, start: bool = ...): ...
    def set_indent(token_class: Any, implicit: bool = ...): ...
    def set_block_scalar_indent(token_class: Any): ...
    def parse_block_scalar_empty_line(indent_token_class: Any, content_token_class: Any): ...
    def parse_block_scalar_indent(token_class: Any): ...
    def parse_plain_scalar_indent(token_class: Any): ...
    tokens: Any = ...
    def get_tokens_unprocessed(self, text: Optional[Any] = ..., context: Optional[Any] = ...): ...

class JsonLexer(Lexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    integers: Any = ...
    floats: Any = ...
    constants: Any = ...
    hexadecimals: Any = ...
    punctuations: Any = ...
    whitespaces: Any = ...
    def get_tokens_unprocessed(self, text: Any) -> None: ...

class JsonBareObjectLexer(JsonLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...

class JsonLdLexer(JsonLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    json_ld_keywords: Any = ...
    def get_tokens_unprocessed(self, text: Any) -> None: ...
