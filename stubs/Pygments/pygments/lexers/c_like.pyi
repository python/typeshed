from pygments.lexer import RegexLexer
from pygments.lexers.c_cpp import CLexer, CppLexer
from typing import Any

class PikeLexer(CppLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class NesCLexer(CLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class ClayLexer(RegexLexer):
    name: str = ...
    filenames: Any = ...
    aliases: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class ECLexer(CLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class ValaLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class CudaLexer(CLexer):
    name: str = ...
    filenames: Any = ...
    aliases: Any = ...
    mimetypes: Any = ...
    function_qualifiers: Any = ...
    variable_qualifiers: Any = ...
    vector_types: Any = ...
    variables: Any = ...
    functions: Any = ...
    execution_confs: Any = ...
    def get_tokens_unprocessed(self, text: Any) -> None: ...

class SwigLexer(CppLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    priority: float = ...
    tokens: Any = ...
    swig_directives: Any = ...
    def analyse_text(text: Any): ...

class MqlLexer(CppLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class ArduinoLexer(CppLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    structure: Any = ...
    operators: Any = ...
    variables: Any = ...
    functions: Any = ...
    suppress_highlight: Any = ...
    def get_tokens_unprocessed(self, text: Any) -> None: ...

class CharmciLexer(CppLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class OmgIdlLexer(CLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    scoped_name: str = ...
    tokens: Any = ...
