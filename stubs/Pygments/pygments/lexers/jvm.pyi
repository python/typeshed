from pygments.lexer import Lexer, RegexLexer
from typing import Any

class JavaLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    tokens: Any = ...

class AspectJLexer(JavaLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    aj_keywords: Any = ...
    aj_inter_type: Any = ...
    aj_inter_type_annotation: Any = ...
    def get_tokens_unprocessed(self, text: Any) -> None: ...

class ScalaLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    opchar: Any = ...
    letter: Any = ...
    upperLetter: Any = ...
    letterOrDigit: Any = ...
    letterOrDigitNoDollarSign: Any = ...
    alphaId: Any = ...
    simpleInterpolatedVariable: Any = ...
    idrest: Any = ...
    idUpper: Any = ...
    plainid: Any = ...
    backQuotedId: str = ...
    anyId: Any = ...
    notStartOfComment: str = ...
    endOfLineMaybeWithComment: str = ...
    keywords: Any = ...
    operators: Any = ...
    storage_modifiers: Any = ...
    tokens: Any = ...

class GosuLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    tokens: Any = ...

class GosuTemplateLexer(Lexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    def get_tokens_unprocessed(self, text: Any) -> None: ...

class GroovyLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    tokens: Any = ...
    def analyse_text(text: Any): ...

class IokeLexer(RegexLexer):
    name: str = ...
    filenames: Any = ...
    aliases: Any = ...
    mimetypes: Any = ...
    tokens: Any = ...

class ClojureLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    special_forms: Any = ...
    declarations: Any = ...
    builtins: Any = ...
    valid_name: str = ...
    tokens: Any = ...

class ClojureScriptLexer(ClojureLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...

class TeaLangLexer(RegexLexer):
    flags: Any = ...
    tokens: Any = ...

class CeylonLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    tokens: Any = ...

class KotlinLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    kt_name: Any = ...
    kt_space_name: Any = ...
    kt_id: Any = ...
    modifiers: str = ...
    tokens: Any = ...

class XtendLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    tokens: Any = ...

class PigLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    tokens: Any = ...

class GoloLexer(RegexLexer):
    name: str = ...
    filenames: Any = ...
    aliases: Any = ...
    tokens: Any = ...

class JasminLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    tokens: Any = ...
    def analyse_text(text: Any): ...

class SarlLexer(RegexLexer):
    name: str = ...
    aliases: Any = ...
    filenames: Any = ...
    mimetypes: Any = ...
    flags: Any = ...
    tokens: Any = ...
